module examples.frege.HelloSpark where

import spark.bindings.JavaSparkContext
import spark.bindings.SparkConf
import spark.bindings.JavaRDD
import spark.bindings.custom.ImmutableSparkConf
import spark.bindings.custom.JavaSparkContextFromImmutableConf

logFile :: String
logFile = "data/first.csv"

sparkLocation :: String
sparkLocation = "~/Documents/Code/spark-2.4.0-bin-hadoop2.7"


--main :: [String] -> IO ()
--main args = do
--  println "World"
    
main :: IO ()
main = do
  --sparkConfig <- SparkConf.new ()
  --sparkConfig.setMaster "local"
  --sparkConfig.setAppName "Frege-Spark"
  --sparkConfig.setSparkHome sparkLocation

  --sc <- JavaSparkContext.new sparkConfig
  
  -- create context from immutable config
  immutableSparkConf = ImmutableSparkConf.new "isc-test"

  isc <-JavaSparkContextFromImmutableConf.new (mutable immutableSparkConf)
  sc <-isc.getSparkContext

  scVersion :: String <- sc.version
  scAppName :: String <- sc.appName

  javaRDD <- JavaSparkContext.textFile sc logFile
  count :: long <- javaRDD.count
  
  -- println $ (show javaRDD.count) -- how to print IO types?

  firstElement <- javaRDD.first
  println $ (firstElement) 

  -- JavaRDD.saveAsTextFile filteredData ("target/testOutput") -- TODO fix error "directory already exists"

  println "Hello Spark from Frege dk"
  println $ "Version: " ++ scVersion
  println $ "AppName: " ++ scAppName
  -- println $ "Count: " ++  show (Long.double count) -- how to make this the right way?