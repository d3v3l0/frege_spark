module examples.IntegrationRDDExample where

import bindings.spark.SparkConf
import bindings.custom.CustomFunction
import bindings.custom.CustomFunction2
--import bindings.Function
--import bindings.Function2
import bindings.testing.TestBindings
import bindings.spark.JavaSparkContext
import config.Config


filterThreeOrFive :: Double -> Bool
filterThreeOrFive 3 = True
filterThreeOrFive 5 = True
filterThreeOrFive _ = false

getSum :: Double -> Double -> Double
getSum x y = x + y


main :: IO ()
main = do
  sparkConfig <- SparkConf.new ()
  list <- arrayFromListST [applicationJar, fregecJar, interpreterJar]
  sparkConfig.setAppName "Frege-Spark"
  sparkConfig.setJars list
  sparkConfig.setMaster "local"
  --sparkConfig.setMaster "spark://Damians-MacBook.local:7077"
  sc :: MutableIO JavaSparkContext <- JavaSparkContext.new sparkConfig

  currentData <- JavaSparkContext.textFile sc "data/first.csv"
  parsedData = currentData.map  Function.convertToDouble
  filteredData = parsedData.filter  Function.filterThreeOrFiveDouble
  --filteredData = parsedData.filter (Function.createFilterFunction filterThreeOrFive)
  -- -> causes Exception in thread "main" org.apache.spark.SparkException: Task not serializable
  --           Caused by: java.io.NotSerializableException: examples.frege.numbers.IntegrationRDDExample$$Lambda$68/1281361915
  mappedData = filteredData.map  Function.timesTenDouble
  sum = mappedData.reduce Function2.getSum
  --sum = mappedData.reduce $ Function2.createFunction2 (getSum)

  currentFirst = currentData.first
  assertEquals "1" currentFirst

  parsedFirst = parsedData.first
  assertEquals 1.0 parsedFirst
    
  filteredFirst = filteredData.first
  assertEquals 3.0 filteredFirst

  mappedFirst = mappedData.first
  assertEquals 30.0 mappedFirst 

  assertEquals 80.0 sum

  scMaster :: String <- sc.master
  println $ "calculated with master: " ++ scMaster
  println "finished IntegrationRDDExample"
