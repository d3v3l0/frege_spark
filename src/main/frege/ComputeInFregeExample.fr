module ComputeInFregeExample where

import JavaSparkContext
import SparkConf
import JavaRDD
--import Util
import CSVUtil
import frege.java.Util
import Function
import Function2
import frege.test.QuickCheck
import DataSet

file :: String
file = "data/cassandraData.csv"

main :: IO ()
main = computeInFrege

add :: Double -> Double -> Double
add a b = a + b

getStringOfMaybe :: Maybe String -> String
getStringOfMaybe (Nothing) = "nothing"
getStringOfMaybe (Just a)  = a

getLocationOfMaybe :: Maybe [String] -> String
getLocationOfMaybe (Nothing) = "nothing"
getLocationOfMaybe (Just as)  = as!!0

filterMaybeForLocation :: Maybe [String] -> Bool
filterMaybeForLocation (Just as)
  | (as!!0 == "GRE") = true
  | otherwise = false
  
myFilter = undefined

toJArray :: List String -> JArray String
toJArray = undefined

convertToDataSet :: [String] -> [DataSet]
convertToDataSet xs = map (CSVUtil.convertLineToDataSet . CSVUtil.csvParseString) xs

filterTemperature :: DataSet -> Bool
filterTemperature ds
  | ds.tre200s0 == "100" = true
  | otherwise            = false

filterHighRain :: DataSet -> Bool
filterHighRain ds
  | (getIntegerOr0FromString ds.rre150z0) > 5 = true
  | otherwise            = false
  
  
filterSTN :: DataSet -> Bool
filterSTN ds
  | ds.stn == "GRE" = true
  | otherwise       = false 


mapGetTemperature :: DataSet -> Double
mapGetTemperature ds = getDoubleOr0FromString ds.tre200s0

--getIntegerFromString :: String -> Integer
--getIntegerFromString s =  String.aton s

getIntegerOr0FromString :: String -> Integer
getIntegerOr0FromString s = case (String.integer s) of
 (Left e) -> 0
 (Right i) -> i
 
--getDoubleFromString :: String -> Double
getDoubleFromString :: String -> (NumberFormatException | Double)
getDoubleFromString s =  String.double s

getDoubleOr0FromString s = case (getDoubleFromString s) of
 (Left e) -> 0
 (Right d) -> d


getSum :: [Double] -> Double
getSum [] = 0
getSum (x:xs) = x + getSum xs 

--getDataOfMutable ::  STMutable t1 (List String) -> List String
--getDataOfMutable (STMutable t1 xs) = xs

computeInFrege :: IO ()
computeInFrege = do
  println "ComputeInFregeExample"
  sparkConfig <- SparkConf.new ()
  sparkConfig.setMaster "local"
  sparkConfig.setAppName "Frege-Spark"
  sc :: MutableIO JavaSparkContext <- JavaSparkContext.new sparkConfig
  currentData :: Mutable s (JavaRDD String) <- JavaSparkContext.textFile sc file
  count <- currentData.count
  println $ show (Long.double count)
  first:: String <- currentData.first
  println $ first
  cp::Mutable t (List String) <- currentData.collect
  elem::Maybe String <- cp.get 0
  iterator:: MutableIO (Iterator String) <- (cp.iterator)
  list :: [String] <- (iterator.toList)
  -- TODO what are the requirements for bindings   --  type is : IO () expected: StringJ t1
	--StringJ is not an instance of Bind
  --println $ ((head $ map (CSVUtil.convertLineToDataSet . CSVUtil.csvParse) list).tre200s0)
  --temp <- ((head $ map (CSVUtil.convertLineToDataSet . CSVUtil.csvParse) list).tre200s0)
  -- println $ ((head $ map (CSVUtil.convertLineToDataSet . CSVUtil.csvParse) list) >>= _.tre200s0)
  --println $ (head (filter filterHighRain (convertToDataSet list)))
--  println $ (head (map mapGetTemperature (filter filterHighRain (convertToDataSet list))))
--println $ (head (filter filterTemperature (convertToDataSet list))).tre200s0
  --println $ (head (filter filterSTN (convertToDataSet list))).stn
  --println $ (head (filter filterSTN (convertToDataSet list))).tre200s0
 -- println "temperaturInt"
  println $ getSum (map mapGetTemperature (filter filterHighRain (convertToDataSet list))) / Int.double (length (filter filterHighRain (convertToDataSet list)))
 --Exception in thread "main" frege.runtime.Undefined: Data.List.!!: empty list indexed (1)
  --println $ head $ head $ map CSVUtil.csvParse list

  --println $ head(CSVUtil.csvParse (head list))
  --println $ getStringOfMaybe elem
  --c <- cp.thaw  

  --cp >>= (return . head) >>= println
 -- println $ head (map csvParse currentData.collect.toList)
  --firstDataSet :: DataSet <- convertLineToDataSet parsedLine
  --println $ first
  --collection <- currentData.collect
--  first <- bind head collection
  println ""

basicSpark :: IO ()
basicSpark = do {
  sparkConfig <- SparkConf.new ()
  ; sparkConfig.setMaster "local"
  ; sparkConfig.setAppName "Frege-Spark"

  ; sc <- JavaSparkContext.new sparkConfig
  ; currentData <- JavaSparkContext.textFile sc file
  ; collectedData <- currentData.collect
  --; putStrLn $ (toJArray collectedData).genericElemAt 0
  ; first <- collectedData.get 0
 -- ; firstp <- parseLine (first)
--  ; putStrLn $ ((filter myFilter (collectedData.toArray)!!0))

  --; putStrLn $ getLocationOfMaybe ((filter filterMaybeForLocation collectedData).get 0)

--  ; putStrLn $ getStringOfMaybe first
    --" type is : StringJ t1 expected: ST t2 t1
	--StringJ is not an instance of Bind
  --; parsedFirst <- (getDataFromMutable (first))
  --; location <- getLocationOfMaybe parsedFirst

  
  --; length <- length currentData
  --; putStrLn $ "Length of array : " ++ (show (Long.double length))
  --; putStrLn $ "Average temperature of measurements with high rain: " ++ (show (averageTemperature / Long.double count))
  ; putStrLn $ "Average"
}